

#### üë∑‚Äç‚ôÄÔ∏è‚ö†Ô∏è Work in Progress ‚ö†Ô∏è üë∑‚Äç‚ôÄÔ∏è


## Dokumentation quenfo_py
***
Die Software **quenfo_py** bietet verschiedene Funktionen zur Verarbeitung von Stellenanzeigen an.
Diese unterteilen sich in die Klassifikation von Stellenanzeigen, in die Informationsextraktion von Kompetenzen und Tools und in Matching-Workflows zum Auffinden bereits bekannter Entit√§ten innerhalb klassifizierter Paragrafen.
In dieser Dokumentation werden die jeweiligen Workflows beschrieben. Dabei werden die einzelnen Schritte und die genutzten Klassen und Methoden aufgef√ºhrt. 
Jede ausf√ºhrbare Applikation arbeitet mit Object Relational Mapping (ORM). Objekte werden hierbei als Datenbankeintr√§ge persistiert, d.h. in den Datenklassen (z.B. in den Klassen ClassifyUnits, ExtractedEntity, InformationEntity oder ExtractionUnit) werden entsprechende Annotationen an Klassenattributen vorgenommen, um diese als vorzunehmenden Eintrag zu kennzeichnen. F√ºr die Realisierung wurde [SQLAlchemy](https://docs.sqlalchemy.org/en/14/orm/) genutzt. 

Die Software entstand im Projekt [Quenfo](https://dh.phil-fak.uni-koeln.de/forschung/qualifikationsentwicklungsforschung) 
und in Kooperation mit dem Bundesinstitut f√ºr Berufsbildung.


**Zielsetzung:**

	a. Stellenanzeigen werden in Paragraphen aufgesplittet und klassifiziert.
			M√∂gliche Klassen: 
			1. Selbstvorstellung des ausschreibenden Unternehmens
			2. Beschreibung der T√§tigkeit, Angebote an die Bewerberinnen und Bewerber
			3. Anforderungen an die Bewerberin bzw. den Bewerber 
			4. Formalia und Sonstiges
			5. 1&3
			6. 2&3
   
	b. Informationsextraktion von Kompetenzen und Tools aus klassifizierten Paragraphen
	c. Matching-Workflows zum Auffinden bereits bekannter Entit√§ten innerhalb klassifizierter Paragrafen.

**Input:**

	Trainingsdaten (SQL-Datenbank mit bereits klassifizierten Stellenanzeigen)
	Input-Daten (SQL-Datenbank mit Stellenanzeigen)

**Hauptstruktur:**

	Textclassification
	Information Extraction
	Matching

**Output:** SQL-Datenbank bestehend aus:

	SQL-Tabelle mit klassifizierten Paragraphen
	SQL-Tabelle mit ExtractionUnits (Tools oder Kompetenzen)
	SQL-Tabelle mit MatchingUnits (Tools oder Kompetenzen)
	
--> Mehr zu Input und Output siehe Ende der Readme

***
### QuickstartüèÉ
***
Die Anwendung wurde in Python 3.7 geschrieben.

Klone das Repository

`git clone https://github.com/agerlac1/quenfo_py.git`

cd in den Ordner **quenfo_py/code**: hier liegt die requirements Datei und das Programm wird von hier ausgef√ºhrt (working dir)

`python -m pip install -r requirements.txt`

Mit der nachfolgenden Ausf√ºhrung wird das gesamte Programm samt Default-Settings aufgerufen (Pfad zu den Trainingsdaten muss zuvor in der config.yaml angegeben werden). 
--> Textclassification, Information Extraction, Matching

`python main.py --input_path "path_to_input_data" --db_mode {overwrite,append}`

Informationen √ºber die erfolgten Abl√§ufe und Ergebnisse werden in dem Modul `/logger` in den entsprechenden logging-Dateien gespeichert.

***
### WorkflowüîÅ
***
Hier kommt der Workflow hin

#### Allgemein

Hier kommt der allgemeine Workflow hin

#### Aufteilung Classification(Aufgeteilt in Training und classification), IE und Matching

Das sind die drei Steps

und hier bitte das Workflow bild einbinden

<img src="docs/quenfo_py.svg"/>


#### Code Struktur
Der Code ist so struktuiert, dass sich die einzelnen Module (im Workflow s.o. erkennbar) ebenfalls in der Ordnerstruktur wiederfinden.
```
üì¶quenfo_py
 ‚î£ üìÇadditional_scripts
 ‚î£ üìÇcode
 ‚îÉ ‚î£ üìÇclassification
 ‚îÉ ‚îÉ ‚î£ üìÇpredict_classes
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúknn_predictor.py
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúregex_predictor.py
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúresult_merger.py
 ‚îÉ ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚îÉ ‚î£ üìÇprepare_classifyunits
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìÇclassify_units
 ‚îÉ ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúconvert_classifyunits.py
 ‚îÉ ‚îÉ ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìÇfeature_units
 ‚îÉ ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúconvert_featureunits.py
 ‚îÉ ‚îÉ ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìÇfeature_vectors
 ‚îÉ ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúconvert_featurevectors.py
 ‚îÉ ‚îÉ ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚î£ üìÇconfiguration
 ‚îÉ ‚îÉ ‚î£ üìúconfig.yaml
 ‚îÉ ‚îÉ ‚î£ üìúconfig_model.py
 ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚î£ üìÇdatabase
 ‚îÉ ‚îÉ ‚î£ üìúconnection.py
 ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚î£ üìÇinformation_extraction
 ‚îÉ ‚îÉ ‚î£ üìÇprepare_extractionunits
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìÇextraction_units
 ‚îÉ ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúconvert_extractionunits.py
 ‚îÉ ‚îÉ ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚îÉ ‚î£ üìÇprepare_resources
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúconnection_resources.py
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúconvert_entities.py
 ‚îÉ ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚îÉ ‚î£ üìúhelper.py
 ‚îÉ ‚îÉ ‚î£ üìúmodels.py
 ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚î£ üìÇlogger
 ‚îÉ ‚î£ üìÇorm_handling
 ‚îÉ ‚îÉ ‚î£ üìúmodels.py
 ‚îÉ ‚îÉ ‚î£ üìúorm.py
 ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚î£ üìÇtests
 ‚îÉ ‚î£ üìÇtraining
 ‚îÉ ‚îÉ ‚î£ üìÇknnclassifier
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúgen_knn.py
 ‚îÉ ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚îÉ ‚î£ üìÇregexclassifier
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúgen_regex.py
 ‚îÉ ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚îÉ ‚î£ üìÇtfidfvectorizer
 ‚îÉ ‚îÉ ‚îÉ ‚î£ üìúgen_vectorizer.py
 ‚îÉ ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚îÉ ‚î£ üìúhelper.py
 ‚îÉ ‚îÉ ‚î£ üìútrain_models.py
 ‚îÉ ‚îÉ ‚îó üìú__init__.py
 ‚îÉ ‚î£ üìúmain.py
 ‚îÉ ‚îó üìúrequirements.txt
 ‚î£ üìÇdocs
 ‚î£ üìú.gitignore
 ‚îó üìúREADME.md
```

***
### Implementierung und Module üõ†Ô∏è
***
#### orm_handling

#### database
1. `connection.py`: Script mit dem die connections zu den SQL-Datenbanken hergestellt werden (Input, Output und Backup-Dateien).

#### tests

#### classification




**main.py**

Main-Skript des Tools. Hier befindet sich die grobe Architektur und Verwaltung des Programms. Des Weiteren sind hier die ArgumentParser Befehle deklariert, mit denen bestimmte Teile des Skriptes aufgerufen werden k√∂nnen (mehr dazu weiter unten).

**requirements**

Enth√§lt eine Auflistung an Python-Dependencies, die ben√∂tigt werden, um das Tool auszuf√ºhren.

**logger**

Logging-Ordner, in dem zus√§tzliche Informationen w√§hrend der Ausf√ºhrung des Tools gespeichert werden. 

**input, output **
Input-Path wird √ºber die CMDLine mitgegeben und Output wird in diese reingeschrieben.

***
### Configurationüìã‚úîÔ∏è
***
In der Datei config.yaml sind alle Pfade, einstellbare Parameter und der Metadaten-Filter vermerkt. Dadurch wird gew√§hrleistet, dass im Code selbst f√ºr eine Anwendung nichts ver√§ndert werden muss. Alle √Ñnderungen werden in der `config.yaml` Datei vorgenommen.

Ansonsten k√∂nnen folgende Werte angepasst werden:

***
### CommandLine - Befehleüì¢
***
Alle Befehle werden relativ zum Ordner `code/` ausgef√ºhrt.

**Grunds√§tzlich:** 

    usage: main.py [-h] [--classification] [--extraction] [--matching]
               [--input_path INPUT_PATH] [--db_mode {overwrite,append}]

    classify jobads and extract/match information

    optional arguments:
    -h, --help            show this help message and exit
    --classification
    --extraction
    --matching
    --input_path INPUT_PATH
    --db_mode {overwrite,append}



***
### Daten - Aufbauüìö
***

####Input
Als Input-Dateien m√ºssen SQL-Datenbanken vorliegen. Die Tabelle mit den enthaltenen Stellenanzeigen sollte bestenfalls den Namen *jobads*  haben oder der neue Tabellenname muss manuell im Script *code/orm_handling/models.py *ge√§ndert werden. Die Daten m√ºssen mindestens √ºber folgende gef√ºllte Spalten verf√ºgen, damit sie als Input-Daten verwendet werden k√∂nnen (egal ob als Test- oder Trainingsdaten):

- id
- content (Text der Stellenanzeige)

Optional:

- postingID
- language
- jahrgang

####Output

Tabelle zur Textclassification:
-  id
- classID
- parentID --> Zu welcher JobAd der Paragraph geh√∂rt
- paragraph

Tabelle zur Information Extraction:
Kompetenzen oder Tools werden als Entit√§ten durch Extraktionsmuster extrahiert
- id
- positionIndex
- paragraph_id
- sentence
- tokenArray

Tabelle zum Matching:
Kompetenzen oder Tools werden durch StringMatching gefunden
- id
- parent_id
- type
- startLemma
- singleWordEntitiy
- lemmaArray
- lemmaExpression
- modifier



